性能： Redis 能读的速度是 110000 次/s，写的速度是 81000 次/s。
不保证强一致性

为什么块：
    1）完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是 O(1)；
    2）数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的；
    3）采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
    4）使用多路 I/O 复用模型，非阻塞 IO；
    5 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；


应用场景：
    计数器
    缓存、会话缓存（缓存不能作为可靠数据来源）
    消息队列：List
    分布式锁：
缓存分类：
    本地缓存：应用和缓存同一个进程内，最快，无需网络开销， 但是不能集群共享，各自维护带来内存开销，实现：
        （1）局部变量（成员变量）或者静态变量（如一个MAP资源）， 还可以结合Zookeeper自动发现机制来实时更新
        （2）缓存框架如Ehcache\Guava Cache等

    分布式缓存： 应用和缓存组件隔离， 可以共享，但是增加了网络开销， 实现：
        （1）memcached： 其客户端采用一致性哈希算法作为路由策略：
                一致性哈希：
                    （1）计算Key 哈希值
                    （2）计算服务器节点的哈希值
                    （3）这些哈希值的范围在一个有限的值域，比如 0 - 2^32
                    （3）服务器哈希值大于 Key哈希值 的最小服务器， 作为该Key的目标服务器， 找不到则最小服务器
        （2）redis
         (3) Spring 注解缓存： 核心依赖Spring AOP， 开箱即用；


集群主从复制：    为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型， 另外也是为了读写分离
数据分片：       哈希槽， hash slot, Redis 集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽.集群的每个节点负责一部分hash槽
数据一致性：     Redis 并不能保证数据的强一致性. 这意味这在实际中集群在特定的条件下可能会丢失写操作， 因为主从复制是异步的， 且会因为网络分区等原因触发从被选主
集群部署配置：     port 7000
                cluster-enabled yes
                cluster-config-file nodes.conf
                cluster-node-timeout 5000
                appendonly yes

Java 客户端： Jedis， Redisson

单线程模型：
    https://it-blog-cn.com/blogs/redis/thread_model.html#%E4%BA%8C%E3%80%81%E6%96%87%E4%BB%B6%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E7%BB%93%E6%9E%84
    Redis 基于 Reactor 模式开发了网络事件处理器，这个处理器被称为文件事件处理器（file event handler）。它的组成结构为 4 部分：
        多个套接字 -> IO 多路复用程序 -> 文件事件分派器 -> 事件处理器(一次调用连接应答处理器、命令请求处理器、命令恢复处理器）
    （1）IO 多路复用程序监听多个socket, 不同socket产生不同事件
    （2）socket事件有序、同步的放在队列中
    （3）文件事件分派处理器每次处理一个套接字（由该套接字关联的事件处理器处理）
    （4）IO 多路复用程序是包装select、epoll、evport、kqueue等函数库实现的， 并且实现了相同的API可以切换， 程序编译的时候会自动选择系统中性能最高的函数库来作为底层实现；
    （5）IO 多路复用程序监听套接字的ae.h/AE_READABLE事件和ae.h/AE_WRITABLE事件
        *客户端对套接字执行 write 或者 close时， 套接字可读， 或者客户端对服务器的监听套接字执行connect操作时产生新的可应答套接字（acceptable）， 套接字会产生AE_READABLE事件
        *客户端对套接字执行 read时， 套接字可写， 套接字产生AE_WRITABLE事件
    （6）连接应答处理器：networking.c/acceptTcpHandler： 作用是对连接"服务器监听套接字"的客户端进行应答， redis初始化的时候，会将其和"服务器监听套接字"的AE_READABLE事件关联。 客户端连接时触发服务器套接字AE_READABLE事件， 引发连接应答处理器执行， 并会将该客户端套接字的AE_READABLE事件关联命令请求处理器。
    （7）命令请求处理器：networking.c/readQueryFromClient：客户端连接创建后， 服务器会将客户端套接字AE_READABLE事件和该处理器关联起来，随后客户端发送命令请求， 客户端套接字产生AE_READABLE事件， 引发命令请求处理器执行（执行相应的套接字读入操作）。执行完后再将客户端套接字的AE_WRITABLE事件和命令回复处理器关联。
    （8）客户端准备好接受数据后， 客户端套接字产生AE_WRITABLE事件， 压入队列， 事件分派器找到命令回复处理器， 在客户端套接字输入结果， 之后解除客户端套接字和回复处理器的关联。

     *注意：这里的客户端套接字还是redis服务器上创建的和客户端通信的socket!!



    。因为文件事件分派器队列的消费是单线程的，所以 Redis 才叫单线程模型。
    文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。
    当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生， 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。
    虽然文件事件处理器以单线程方式运行， 但通过使用 I/O 多路复用程序来监听多个套接字， 文件事件处理器既实现了高性能的网络通信模型， 又可以很好地与 redis 服务器中其他同样以单线程方式运行的模块进行对接， 这保持了 Redis 内部单线程设计的简单性。


哨兵机制：
    定义：Redis 哨兵（Sentinel）是运行在特殊模式下的 Redis 服务器，不支持读写操作，它的作用是配合 Redis 的复制功能，实现对主从节点的监控、对下线的主节点进行故障转移和通知。
    与redis集群独立， 监控所有节点的状态， 发现master线下后重新选主，并向客户端发送通知
    哨兵也是集群部署模式，不是一个哨兵判断master下线就会重新选主，而是一般需要超过一半的哨兵都认定下线才会执行
    三种监控机制： INFO指令、发布哨兵通道、PING
    哨兵之间怎么通信呢，哨兵通过订阅主库上的_sentinel__频道，可以将自己的IP地址和端口信息发布，如果有主库的状态变化也会发布（每2秒）
    此外每个哨兵每一秒还会向其他哨兵和主从节点发送PING看是够联通， 心跳检测
    哨兵配置了主库，但是怎么和从库建立连接的呢， 也是通过给主库发送INFO命令实现的
    （1）哨兵对所有节点（主从）都会每隔 10s 发送一次 INFO 命令；
    （2)主库没有在规定时间内相应视为下线状态，选择一个从库作为新的master；
    （3）通知其他从库，让其执行replicaof命令， 与主库建立新连接并进行数据同步
    （4）此外还会通知客户端这个新的master让其重新建立连接




持久化方式：
    RDB（Redis DataBase）: 指定的时间间隔内将内存中的数据集以快照的形式写入磁盘, 回复时直接读入内存
        folk 一个子线程进行全量持久化
        二进制序列化保存
        性能极高，但是最后一次持久化后的数据会丢失
        注意主从复制也是基于RDB快照的
        如何利用RDB文件回复：将dump.rdb文件移动到redis安装目录启动服务即可
        （1）自动触发：配置， 如 save 300 10 表示300秒内超过10个Key被修改，发起快照， 执行bgsave命令。 默认关机的时候如果没有开启AOF也会自动执行
        （2）手动触发：save命令阻塞服务器， 暂时不能处理其他指令，bgsave命令则是后台异步， 优先使用。
        问题： 不能实时持久化，频繁执行成本较高尤其是内存压力
    AOF(Append Only File): 以日志的形式来记录每个写操作, 只增不改，保存在appendonly.aof文件中
        实现了实时持久化， 数据更加安全
        开启启动回复AOF： appendonly yes

        工作机制：
            （1）写命令执行，纯文本格式保存在缓存区（aof_buf)的末尾
            （2）调用flushAppendOnlyFile方法，将缓存区中的内容保存在AOF文件中
            （3）AOF文件重写：随着文件的变大，增加了重写机制（不读文件直接根据内存数据保存命令）， 可以优化命令压缩AOF指令，当文件大小超过限值后；对应指令bgrewriteaof
        redis进程需要实时调用fsync函数，强制刷新到磁盘，这样可以保证AOF日志不丢失（缓存区丢失）， fsync策略有：
            （1）每次修改同步：appendfsync always， 性能较差
            （2）每秒同步：appendfsync everysec 性能较好
            （3）不同步：appendfsync no
        问题： 回复数据耗时长， 文件比较大， 且使用fsync策略性能稍差

    redis数据恢复优先级： AOF <- RDB, 前者更完整
    如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式






redis数据类型：
    String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）、Stream
    String: 简单动态字符串（SDS）
    List: LinkedList（双向链表）、ZipList（压缩列表）、QuickList（快速列表） （3.2以后List 的底层实现变为 QuickList。
    Hash： Dict、ZipList
    Set: Dict、Intset (整数集合)
    Zset： ZipList（压缩列表）， SkipList（跳跃表）

    相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）
    strign 的一些指令： SET、GET、 INCR、DECR
    List 常见指令： LPUSH、RPUSH、LPOP、RPOP、LSET(指定索引）、LLEN、LRANGE(分页）
    Hash: 数组 + 链表， 常见指令：HSET、HGET、HMSET、HEXISTS、HLEN、HGETALL、
    SET: 无序唯一集合， Set 轻易实现交集、并集、差集的操作！常见指令： SADD、SCARD（数量）、SMEMEBER(所有元素)、SISMEMBER、SUNION(并集）、SINTER(交集)、SDIFF(差集)
    Sorted Set 类似于 Set，但和 Set 相比，Sorted Set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。
    Sorted Set 常见指令：ZADD、ZSCORE、ZCARD、ZRANGE(按权重排序)、ZREVREANGE(逆序)、ZREVRANK(指定元素排序）， 需要随机获取数据源中的元素根据某个权重进行排序的场景，举例：各种排行榜比如直播间送礼物的排行榜、朋友圈的微信步数排行榜、王者荣耀中的段位排行榜、话题热度排行榜等等。

    压缩列表：连续编码的内存块
    快速列表：快速列表(quicklist)可以看成是双向链表和压缩列表的一种组合。
    整数集合：整数集合(intset) 是Set键底层实现之一，当一个集合只包含整数元素的时候，Redis会使用整数集合作为集合键的实现。
    跳跃表(skiplist )是一种有序数据结构，它在每个节点中维护多个指向其他节点的指针，从而可以快速访问。其支持平均O(logN) 复杂度的节点查找。
    Zset使用了跳跃表和字典作为其底层实现。其好处就是可以进行高效的范围查询， 可以简单理解为多层索引
    跳跃表的重要概念： 跳表的空间复杂度是O(n)，时间复杂度是O(logn)。层数（每个节点有多个）、跨度SPAN（该层索引跨度）、Forward前向指针（每层一个），Backward后退指针（每个节点一个），score，跳表是一个值有序的链表建立多级索引之后的一种数据结构，通过上述的查找方式，我们可以看到类似于二叉查找树的查找方式，所以说跳表查找类似于链表的“二分查找”算法。
    向右（不行后退）- >向下 找到





分布式锁：需要满足的基本要求（1）安全属性，独享：任何时刻只有一个客户端持有锁；（2）无死锁，当因为客户端崩溃或者网络分裂， 锁还能被其他客户端获取到 （3）可用性，容错， 只要大部分节点存活就能够正常获取和释放锁；
        实现Redis分布式锁的最简单的方法就是在Redis中创建一个key，这个key有一个失效时间（TTL)，以保证锁最终会被自动释放掉（这个对应特性2）。当客户端释放资源(解锁）的时候，会删除掉这个key。但是上面存在一个问题：
        单点失败：A 获取锁后， master还没有复制到salve（异步）， 这个时候master挂了， salve被选为主， 则B也可以获取同一个锁， 导致安全失效！

        单实例锁：SET resource_name my_random_value NX PX 30000， eval方法释放（luna脚本解释执行, 三个参数， 脚本， key数量， keys）， 不同客户端给Key赋值不同， 释放的时候会比较value不会误释放其他客户端正在占用的锁； 脚本例子
                		if redis.call("get", KEYS[1]) == ARGV[1] then
                			return redis.call("del", KEYS[1])
                		else
                			return 0
                		end`
        多实例算法：（ReadLock): 假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制, 为了取到锁，客户端应该执行以下操作:
            获取当前Unix时间，以毫秒为单位。
            依次尝试从N个实例，使用相同的key和随机值获取锁。在步骤2，当向Redis设置锁时,客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试另外一个Redis实例。
            客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。
            如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。
            如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功）。
            ** 理想情况下， 一个客户端应该同时向所有实例发送Set命令，如果获取失败了应该在一个随机延迟后重试,防止多个客户端在同时抢夺同一资源的锁（这样会导致脑裂）
            ** 异常情况下， 一个已经获取锁的节点重启，如果没有备份，可能会导致其他客户端也能获取锁， 理论上为保证锁的安全性，应该fsync=always，开启备份， 另外重启后的节点暂时不参与锁获取（不可用）也可以达到目的。即所谓延迟重启。

回收策略：
    当maxmemory限制达到的时候Redis会使用的行为由 Redis的maxmemory-policy配置指令来进行配置。以下的策略是可用的:
    noeviction:         返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）
    allkeys-lru:        尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。
    volatile-lru:       尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。
    allkeys-random:     回收随机的键使得新添加的数据有空间存放。
    volatile-random:    回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。
    volatile-ttl:       回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。
    * 可以在运行时进行相关的策略调整，并且监控缓存命中率和没命中的次数，通过RedisINFO命令输出以便调优。

    redis中的LRU不是真正意义上的， 没办法选择最佳候选来进行回收（消耗太大的内存和CPU时间)，也就是最久未被访问的键。相反它会尝试运行一个近似LRU的算法，通过对少量keys进行取样，然后回收其中一个最好的key（被访问时间较早的）， 这个取样的效果在数据近似为幂定律的访问模式的时候， 没有很大差别
    这个样本数量可以通过指令指定：maxmemory-samples 5

数据到期删除：
    Redis keys过期有两种方式：被动和主动方式。
    当一些客户端尝试访问它时，key会被发现并主动的过期。
    当然，这样是不够的，因为有些过期的keys，永远不会访问他们。 无论如何，这些keys应该过期，所以定时随机测试设置keys的过期时间。所有这些过期的keys将会从密钥空间删除。
    具体就是Redis每秒10次做的事情：
    测试随机的20个keys进行相关过期检测。
    删除所有已经过期的keys。
    如果有多于25%的keys过期，重复步奏1.

    **超时后只有对key执行DEL命令或者SET命令或者GETSET时才会清除。 这意味着，从概念上讲所有改变key的值的操作都会使他清除

管道：
    Redis是一种基于客户端-服务端模型以及请求/响应协议的TCP服务
    一次请求/响应服务器能实现处理新的请求即使旧的请求还未被响应。这样就可以将多个命令发送到服务器，而不用等待回复，最后在一个步骤中读取该答复。这就是管道（pipelining）
    管道的作用是：减少客户端和服务端之间交互的耗时，不过这依赖服务端维护一个返回队列， 相应会占据内存
    当然大部分 pipeline 应用场景可通过 Redis 脚本（Redis 版本 >= 2.6）得到更高效的处理


发布订阅：

内存优化：
    内存压缩： 存储集合数据的时候会采用内存压缩技术，以使用更少的内存存储更多的数据。如Hashes,Lists,Sets和Sorted Sets，当这些集合中的所有数都小于一个给定的元素，并且集合中元素数量小于某个值时，存储的数据会被以一种非常节省内存的方式进行编码，使用这种编码理论上至少会节省10倍以上内存（平均节省5倍以上内存）。并且这种编码技术对用户和redis api透明
    小散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key,而是应该把这个用户的所有信息存储到一张散列表里面.
    散列表中嵌入对象是不允许的，散列表字段设置单独的过期时间是不允许的
    每次散列表的元素数量或者值超过了阈值，散列将被扩展为一张真正的散列表进行存储，此时节约存储的优势就没有了

Redis事务：
    MULTI（开启事务） 、 EXEC 、 DISCARD 和 WATCH 是 Redis 事务相关的命令
    事务特性：
        事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。
        事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。
    发生在 EXEC 执行之前的错误，（入队失败或者拒绝执行） ： 客户端以前的做法是检查命令入队所得的返回值：如果命令入队时返回 QUEUED ，那么入队成功；否则，就是入队失败。如果有命令在入队时失败，那么大部分客户端都会停止并取消这个事务。不过，从 Redis 2.6.5 开始，服务器会对命令入队失败的情况进行记录，并在客户端调用 EXEC 命令时，拒绝执行并自动放弃这个事务。
    在EXEC 命令执行之后所产生的错误， 并没有对它们进行特别处理： 即使事务中有某个/某些命令在执行时产生了错误， 事务中的其他命令仍然会继续执行。
    为什么 Redis 不支持回滚：从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。
    WATCH命令使得事务可以有条件执行：WATCH 命令可以为 Redis 事务提供 check-and-set （CAS）行为。被 WATCH 的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在 EXEC 执行之前被修改了， 那么整个事务都会被取消， EXEC 返回nil-reply来表示事务已经失败。

Redis 大KEy的处理：
    危害： 占用内存大、操作耗时，网络阻塞
    原因： 超大字符串、超大对象
    方法：
        （1）大的Key拆开存取，
        （2）使用哈希存储


布隆过滤器：二进制向量和一系列随机映射函数， 空间和时间上有巨大的优越性，也不需要存储数据有一定的保密性
    它可以告诉你某样东西一定不存在或者可能存在
    相比于传统的MAP或者SET， 占据空间更小更高效，但是结果不是精确的（存在不一定）
    底层是bitMap数据结构(每一byte标志对应数字是否存在。 减少内存）
    工作机制：
        （1）给定Key, 经过多个hash()， 每个哈希值的位置设置成1，
        （2）查询Key, 每个hash()计算， 相应哈希值的位置如果是0 ，则一定不存在
    问题：随着数据的增多，误算率越来越大，减少的方法
        增加二进制位数，增加哈希的次数（增加数据的特征）
    使用：redission中内置了布隆过滤器


性能优化：
    master上最好不要做持久化工作， slave上可以开启AOF备份数据， 策略每秒一次， Master和slave最好在一个局域网内；主从复制不要使用图形结构尽量线性切换主快捷





