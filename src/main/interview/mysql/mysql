基础：
    （1）MySQL 服务支持的最大连接数由 max_connections 参数控制，

https://xiaolincoding.com/mysql/base/how_select.html#mysql-%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84
索引下推：
    一般情况：
        引擎按索引查询到数据后（满足要求的第一条），先回表，然后将完整记录返回给Server,server 层判断索引外的条件，如果满足则返回给客户端，之后引擎继续查找：
    索引下推：
        如果引擎查找到数据后， 不先回表， 而是根据索引的其他字段（联合所以中没有引用的字段）进行条件判断，满足要求再去回表， 从而减少很多回表操作，提升性能

MYSQL数据存储：
    （1）表文件存储在.idb中， 表空间由段（segment）、区（extent）、页（page）、行（row）组成
    （2）数据库读取的单位是也page, 默认是16KB连续空间
    （3）在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了。
    （4）段包括：
            数据段：存放 B + 树的叶子节点的区的集合
            索引段：存放 B + 树的非叶子节点的区的集合；
            回滚段：存放的是回滚数据的区的集合
    （5）数据行：InnoDB 提供4种行格式，分别是 Redundant、Compact、Dynamic和 Compressed
            （1）Compact： 紧凑格式
            （2）Dynamic： compact格式的改进 5.7以后默认
            （3）Compressed: compact格式的改进
            （4）Redundant： 非紧凑，已经不用了
    （6）COMPACT格式：
            （1） 变长字段长度列表：按列顺序的逆序存放， 不保存null的变长字段长度
                    逆序原因：使得位置靠前的记录的真实数据和数据对应的字段长度信息可以同时在一个 CPU Cache Line 中，这样就可以提高 CPU Cache 的命中率。
            （2） NULL 值列表：必须用整数个字节的位表示（1字节8位）， 也是逆序存放， 一位表示一个字段， 0表示非null
            （3） 记录头信息：包含多个信息
                    delete_mask： 记录是否被删除标志
                    next_record： 下一条记录的位置
                    record_type： 记录的类型， 普通数据、B+树非叶子节点记录、最小记录等

            （4） row_id：      如果没有指定ID或者主键默认有这个字段 6 字节
            （5） trx_id：      数据由哪个事务生成的， 6字节
            （6） roll_pointer：数据上一版本指针， 7字节

            （7）真实数据： 字段值
    （7）长度限制：
            MySQL 规定除了 TEXT、BLOBs 这种大对象类型之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过 65535 个字节。
            这个65535包括「变长字段长度列表」和 「NULL 值列表」

            varchar(n) 字段类型的 n 代表的是最多存储的字符数量，并不是字节大小， 所以varchar(n)的大小要看对应字符集一个自字符的字节数
                例如：在 UTF-8 字符集下，一个字符最多需要三个字节，varchar(n) 的 n 最大取值就是 65532/3 = 21844
    （8）溢出页：
        当一行不能放在一个数据页中发生行溢出，多的数据就会存到另外的「溢出页」中。这个时候数据行中还会增加一个字段执行溢出页的地址




数据库查询的流程：
    （1）建立连接
    （2）查询缓存（QueryCache)， 如果缓存存在直接返回结果， 因为数据表更新会自动失效表缓存所以不适合频繁更新的表， Mysql8已经去掉了缓存
    （3）SQL解析和预处理（字段表是否存在）：解析成一棵解析树
        主要是语法、词法、字段等检验和权限校验， 并由优化器生成执行计划（优化器的作用包括决定索引使用和表连接顺序等）， MySQL使用基于成本的优化器
    （4）调用存储引擎的API执行查询

客户端和服务端的数据传输：
    MySQL 客户端/服务器通信协议是半双工的， 同一时刻要么是服务器向客户端发送数据，要么是由客户端向服务端发送数据， 且传输开始后不能主动终止

数据库变更的流程： 与查询类似， 增加了两个日志的操作过程
    （1）建立连接
    （3）SQL解析和执行计划优化
    （3）存储引擎执行计划：
            （1）引擎写入新行（暂时没有更新到磁盘，而是等后续空闲时间再进行）
            （2）将更新后的数据行更新到内存
            （3）同时更新到redo log(也是写入磁盘，顺序写入，比较快)中， 这是redo log状态为 prepare, 为待提交状态
            （4）执行器收到通知后，生成binlog， 然后调引擎事务提交接口。
            （5）引擎将 redo log的状态修改为 commit状态， 更新完成
        这里redo log的两阶段提交是为了保证两个日志的一致性！

     WAL （Write-Ahead Logging）技术
     WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。
     在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。
     问题：为啥redo日志也需要持久化，性能会提升？因为顺序写速度很快
case:
    具体更新一条记录 UPDATE t_user SET name = 'xiaolin' WHERE id = 1; 的流程如下:

    执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：
    如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；
    如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。
    执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：
    如果一样的话就不进行后续更新流程；
    如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；
    开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。
    InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 WAL 技术，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。
    至此，一条记录更新完了。
    在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。
    事务提交，剩下的就是「两阶段提交」的事情了，接下来就讲这个。

Redo 日志： 持久性保证
    为什么需要：
        为了避免每次Update的时候都操作磁盘， InnoDB 会在适当的时候，将 redo log 中的记录更新到磁盘中
    特点：
        执行引擎层面的， 物理日志（在某个数据页做了什么修改）， 固定大小（一组四个文件4GB， 环状写入， 写满之后（也就是 write pos追上 check point的时候）会擦除部分，这些数据会持久化到磁盘中
        有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。
    记录时间：
        记录的是事务发起后的操作
    作用：
        宕机或者故障后的数据恢复





Binlog :
    特点：
        MYSQL服务其层面（MYSQL整体可以分成server和引擎两部分）的逻辑日志， 主要用于归档， 早期没有引擎的时候就有了， redo 日志的主要作用是补充提供了crash-safe能力！
    记录时间：
        事务提交之后的操作语句
    作用：
        数据恢复 、 主从之间复制（主从复制目前主要有异步复制和半同步复制两种方式， 同步复制性能太差几乎不用）
    格式：
        binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED， 分别是原始操作（一些比如时间之类的动态函数可能不一致）、最终行结果（日志文件会很大）和混合
    和Redo的写入方式不同：
        binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。Redo是循环写
    持久化：
        MySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率：
        sync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；默认
        sync_binlog = 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync； 效率最差
        sync_binlog =N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。

Undo log: 原子性保证
    特点：
        引擎层面， 逻辑日志， 主要用于回滚，数据修改的时候除了redo日志， 还会保存一个undo日志， 记录的修改之前的值
    记录时间：
        事务执行期间，未提交
    作用：
        （1）事务回滚
        （2）MVCC:
            当读取的某一行被其他事务锁定时，它可以从 undo log 中获取该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取。
            每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id：
                通过 trx_id 可以知道该记录是被哪个事务修改的；
                通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为版本链；
    什么时候更新到磁盘的：
        undo log 和数据页的刷盘策略是一样的，都需要通过 redo log 保证持久化。
        buffer pool 中有 undo 页，对 undo 页的修改也都会记录到 redo log。redo log 会每秒刷盘，提交事务时也会刷盘，数据页和 undo 页都是靠这个机制保证持久化的。


MVCC :



MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。
    另外，undo log 还有一个作用，通过 ReadView + undo log 实现 MVCC（多版本并发控制）。

    对于「读提交」和「可重复读」隔离级别的事务来说，它们的快照读（普通 select 语句）是通过 Read View + undo log 来实现的，它们的区别在于创建 Read View 的时机不同：

    「读提交」隔离级别是在每个 select 都会生成一个新的 Read View，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。
    「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View，这样就保证了在事务期间读到的数据都是事务启动前的记录。



索引：
    （1）数据的目录，快速找到数据的数据结构
    （2）索引分类：
            按数据结构： B+树索引、哈希所以、全文索引（Full_Text)
            按物理存储： 聚簇索引（主键索引），非聚簇索引（二级索引）
            按字段特性：主键索引、唯一索引、普通索引、前缀索引
            按字段个数： 单列索引、联合索引
    （3）InnoDB的索引规则：主键索引和二级索引都是默认使用B+树
        如果指定主键， 作为聚集索引的KEY
            没有指定，则找一个不为NULL的唯一列作为聚集索引的KEY
                都没有则自动生成一个隐式的自增 id 列作为聚簇索引的索引键（key）
    （4）B+树的构造：
        多叉树， 叶子节点存数据，非叶子节点只存索引， 节点中数据按主键顺序存放， 每一个叶子节点都有指向上一个和下一个的指针（叶子结点构成双向链表）
        相比较二叉树的查询效率很高， 千万级的表查询目标数据最多需要 3-4 次磁盘 I/O
        二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。
        优势：
            （1）相对于B树，非叶子节点也寸数据， 非叶子节点数据量更小， 减少IO
            （2） log2N VS logdN 相比较二叉树的查询效率很高， 千万级的表查询目标数据最多需要 3-4 次磁盘 I/O
             (3) Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。但是 Hash 表不适合做范围查询，它更适合做等值的查询，这也是 B+Tree 索引要比 Hash 表索引有着更广泛的适用场景的原因。
    （5）覆盖索引
        先查询二级索引的B+树获取主键，再查询主键索引的B+树获取完整数据的过程叫回表， 如果不需要回表，在二级索引中就包含全部数据称为覆盖索引

    （6）前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。
        目的是为了减少索引占的空间：INDEX(column_name(length))

    （7）使用联合索引的时候：   多个字段是按顺序编序的，所以必然存在最左匹配， 只有第一个字段是全部有序的。
        另外需要注意：范围查询字段的后面的字段无法用到联合索引，但是也不是完全不会用如下case
        要想知道联合索引用到了几个字段可以看执行计划中的 key_len字段
        （1）select * from t_table where a > 1 and b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？ 只有a
         (2) select * from t_table where a >= 1 and b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？ab都用到了， 因为在a=1的时候可以根据b=2过滤，
        （3）SELECT * FROM t_table WHERE a BETWEEN 2 AND 8 AND b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？都用了同上
        （4）SELECT * FROM t_user WHERE name like 'j%' and age = 22，联合索引（name, age）哪一个字段用到了联合索引的 B+Tree？都用了， 因为J开头的数据中都是相邻存储的， 这个范围内的每一个name下的age是有序的。

        小结：
            联合索引的最左匹配原则，在遇到范围查询（如 >、<）的时候，就会停止匹配，也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。注意，对于 >=、<=、BETWEEN、like 前缀匹配的范围查询，并不会停止匹配，

    （8）索引下推：
        Extra 字段 = Using index condition

    （9）建议：  经常变化的字段不要索引、区分度不高的字段不要索引， 分组排序不涉及的字段不要索引

    （10） Explain:
        (1)Type字段：效率从低到高， 要尽量避免全表和全索引表的扫描， 尽量range以上
            All（全表扫描）；
            index（全索引扫描）；
            range（索引范围扫描）；
            ref（非唯一索引扫描）；
            eq_ref（唯一索引扫描）；（eq_ref 通常用于多表联查中）
            const（结果只有一条的主键或唯一索引扫描）。
        （2）extra字段：
            Using filesort： 文件排序
            Using temporary：临时表多在分组和排序的时候需要
            Using index 所需数据只需在索引即可全部获得，不须要再到表中取数据，也就是使用了覆盖索引，避免了回表操作，效率高

    （11）表的大小：
        （1）ID本身大小有限制，int 32位在21亿左右， bigInt范围很大，完全不用考虑
        （2）加上索引和其他非数据空间（不是全部16k都是数据）估算：一个索引页一般在1600条记录， 一个叶子节点一般在15左右， 三层的话，1600 * 1700 * 15 ～ 2000万左右， 更多数据会导致索引层数增加

    （12）索引失效的原因
        （1）对索引使用左或者左右模糊匹配
        （2）对索引字段使用函数： 如有需要可以再新建一个函数计算后结果值的索引解决）
        （3）对索引进行表达式计算： 比如 where count + 1 > 100
        （4）对索引隐式类型转换： 比如char字段 where name  = 100 不过如果int字段使用字符串可以的 如 where id = '1'可以走索引
        （5）不满足最左匹配
        （5）OR关键词时：如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效， 也即只要有条件列不是索引列，就会进行全表扫描。
    （13）count:
        作用：
            count（col_name）该函数作用是统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个。
            count（1）统计记录数量
            count(*)和count（1）流程几乎一致没有差别
        注意：
            所以，如果要执行 count(1)、 count(*)、 count(主键字段) 时，尽量在数据表上建立二级索引，这样优化器会自动采用 key_len 最小的二级索引进行扫描，相比于扫描主键索引效率会高一些。
            如果是count(col_name)来获取数量， 需要全表扫描扫描， 效率很低
        为什么是扫描的：
            而 InnoDB 存储引擎是支持事务的，同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的，所以无法像 MyISAM一样，只维护一个 row_count 变量。

        也可以估算：
        （1） show table status 或者 explain 命令来表进行估算。
        （2）或者另外存储这个数量值




事务
    （1） ACID:
            (1)原子性：undo日志保证
           （2）一致性： 事务执行前后（期间），数据库的状态是一致的，是完整性约束： 其他三个特性共同保证
           （3）隔离性： 锁或者MVCC
           （4）持久化； 事务提交后的结果不会因为鼓掌丢失  redo日志保证
    （2）并发问题：
            （1）脏读： 事务A 读到了事务B的为提交的修改， 如果事务B回滚了，那就产生了脏读， 即不可靠读
            （2）不可重复读：事务A在事务执行期间，多次读取同一个数据， 前后数据不一致
            （3）幻读： 事务期间，按条件查询结果记录数量前后多次查询结果不同
    （3）四种隔离级别：
            （1）读未提交：三种并发问题都有
            （2）读提交：不会出现脏毒
            （3）可重复读： innodb 默认， 还会出现幻读
            （4）串行化：读写锁控制事务串行等待
    （4）读快照： 解决读提交和可重复读隔离级别依赖的重要机制
            区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。
            「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View
            而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。

            读快照的重要字段：
                （1）m_ids:           创建快照时，当前数据库中「活跃事务」的事务 id 列表
                （2）creator_trx_id： 创建该快照的事务ID
                （3）min_trx_id：     创建快照时， 当前数据库中「活跃事务」中事务 id 最小的事务
                （4）max_trx_id:      创建快照时， 当前数据库中应该给下一个事务的 id 值
            另外涉及的数据列中的两个隐藏字段：
                （1）trx_id:          修改当前数据的事务ID
                （2）roll_pointer:    指向每一个旧版本记录(undo log)

            当访问一个数据记录的时候会有下面的情况：
                （1）trx_id < min_trx_id, 说明该读快照版本是在这些活动事务创建之前创建的， 自然该版本对于本事务可见
                （2）trx_id >= max_trx_id, 说明该读快照版本是在这些活动事务创建志后创建的， 自然该版本对于本事务不可见
                （3）min_trx_id <= trx_id < max_trx_id, 需要分情况：
                        * 如果trx_id 在 m_ids列表中， 说明该版本创建时， 数据事务还在活跃中没有提交， 该版本对于本事务不可见
                        * 如果trx_id 不在 m_ids列表中， 说明该版本创建时， 数据事务已经提交，该版本对本事务可见
            这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。


            ********************在可重复度隔离级别中通过MVCC 解决了幻读的问题，在串行里面是通过next-key lock（记录锁+间隙锁）解决的， 也称为当前读

    （5）可重复度：
            事务启动的时候生成一个读快照，整个事务期间都使用这个快照
    （6）读提交：
            在每次读取数据时，都会生成一个新的 Read View
            case
                （1）数据记录当前事务ID = 1, 值为100
                （2）事务A 启动 ID = 2， 快照中的活跃列表只有 2， min = 1, max = 2， 读取数据事务ID   =  1， 值是100， 可见
                （3）事务B 启动 ID = 3,  快照中的活跃列表 = 2, 3， min = 1, max = 4， 读取数据事务ID = 1， 值是100， 可见

                （4）事务A 修改数据为200， 还没有提交, 此时数据事务ID = 2 值是 200，
                （5）事务B 读数据， 创建新快照活跃列表 = 2，3, min = 1, max = 4 , 数据事务ID= 2， 值是200， 因为2在1-4之间， 并且在活跃列表中说明没有提交， 所以不可见， 需要追溯上一个读快照
                （6）事务A 提交
                （7）事务B 读数据， 创建新快照活跃列表 = 3， min = 3, max = 4, 数据事务ID= 2， 值是200， 因为 2 < 3, 所以可见。
    （7）MySQL幻读
        并没有通过MVCC和锁（当前读）彻底解决
        出现的常见主要是在事务中同时存在常规select 和 更新或者forUpdate之类的当前读， 当前读一定是最新的， 所以有可能会出现幻读！
        这种情况避免可以通过启动事务后立即执行for update 的方式来（next-key lock）解决避免其他事务插入数据并提交


MYSQL锁：
    （1） 锁的类别
            （1）全局锁： 整个数据库不能更新操作， 用于数据备份
            （2）表级锁：
                    表锁： 包括共享锁和独占锁， 如果加了共享锁整个表只读， 这个只读也包括加锁的线程。
                    元数据锁：确保其他线程不会再本线程执行CRUD等操作的时候变更表结构， 不需要显示调用，
                    意向锁：包括意向共享锁和意向独占锁， 和表锁会冲突（意向锁的目的是为了快速判断表里是否有记录被加锁）
                    AUTO-INC 锁： 自增主键锁是再给插入新记录赋值后就释放了，不会等待事务执行完毕，是轻量级的锁。
            （3）行级锁：（普通Select不会加行级锁）
                    Record Lock： 记录锁， 包括X锁和S锁， 即共享锁（in share mod) 和独占锁( for update)
                    Gap Lock：    间隙锁（不包括自己）, 在可重复的隔离级别下解决幻读问题， 多个事务可以包含共同间隙范围的间隙锁，并不存在互斥关系
                                         不是所有情况插入都会加间隙锁， 当索引列是唯一所以只会加记录锁
                    Next-Key Lock： Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身
    （2）插入的流程：
            （1）插入前先查看插入位置是否被其他事务插入间隙锁
            （2）如果插入，则阻塞， 需要等其他事务释放间隙锁。并且添加一个插入意向锁（可以视为一种特殊的行级锁， 一种只有一个点的间隙锁， insert时才用）
                    注意：插入意向锁 和间隙锁会冲突， 也就是不能在拥有间隙锁的情况下， 再去开启新事务占有插入意向锁。

            注意：
                如果 update 语句的 where 条件没有用到索引列，那么就会全表扫描，在一行行扫描的过程中，不仅给行加上了行锁，还给行两边的空隙也加上了间隙锁，相当于锁住整个表，然后直到事务结束才会释放锁。
                需要尽量避免， 影响事务
             死锁case：
                如果事务A和事务B都获取到了一个间隙锁（间隙锁是兼容的）， 比如使用select for update（避免幻读书）， 然后都执行下一步插入，需要获取插入意向锁， 这个
                时候会因间隙锁冲突，都等待释放间隙锁后， 才能获取到插入意向锁。

                解决方法是：
                    避免间隙锁的产生， 间隙锁会阻塞Insert
                    避免查询（forUpdate）、更新或者删除不存在的记录，虽然更新存在的记录也会产生间隙锁，但是间隙锁锁住的范围会更小；更新不存在的记录会锁住意想不到的区间范围，极其容易导致死锁问题
    (3)加锁的一些细节：select * from performance_schema.data_locks\G 语句可以查看加锁细节
            (1) 加锁是加载索引上的， 基本单位是Next-Key lock ,
            (2) 除非是在某些情况下，使用记录锁或者间隙锁就能避免幻读， next-key lock 就会退化成记录锁或间隙锁
                （1）唯一索引， 等值查询， 且记录存在， 退换成记录锁
                （2）唯一索引， 等值查询， 且记录不存在，找到第一条大于查询值的记录后，退化成间隙锁
                （3）唯一索引， 范围查询， 会对每一个扫描到的索引加 next-key 锁，然后又基于情况，会退化成记录锁或者间隙锁：
                （4）非唯一索引， 等值查询， 二级索引上扫描的时候先加Next-Key lock， 如果存在主键上加记录锁， 第一个不存在的退化成间隙锁
                （5）非唯一索引， 范围查询， 二级索引上扫描的时候都是Next-Key lock，不会退化
                （6）无索引的列， 全表扫描， 每一行都会加锁next-key

            在线上在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了
            解决方法：
                （1）加索引
                （2） sql_safe_updates 设置为 1 时。预防
                   update 语句必须满足如下条件之一才能执行成功：
                        使用 where，并且 where 条件中必须有索引列；
                        使用 limit；
                        同时使用 where 和 limit，此时 where 条件中可以没有索引列；
                    delete 语句必须满足以下条件能执行成功：
                        同时使用 where 和 limit，此时 where 条件中可以没有索引列；
                 （3）为了避免优化器的优化不走索引可以强制走索引： force index([index_name])




Buffer pool
    （1）Buffer Pool 是在 MySQL 启动的时候，向操作系统申请的一片连续的内存空间，默认配置下 Buffer Pool 只有 128MB
    （2）InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的16KB的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页。
    （3） 除了缓存「索引页」和「数据页」，还包括了 undo 页，插入缓存、自适应哈希索引、锁信息等等。
    （4）缓存更新使用LRU
















