
消息中间件的作用和价值：
    （1）优化系统性能：平衡不同系统性能差异
    （2）系统结耦： 避免因为下游系统的故障不可用而影响本系统的正常功能
    （3）削峰填谷： 在大流量的情况下，可以避免后台系统处理不及时超出能力的情况
    （4）消息通信：

目前主流的消息中间件工具：Kafka、RabbitMQ、RocketMQ
    （1）Kafka:
            高吞吐量（但实例数十万QPS）
            高性能
            可集群部署
        问题：
            可能存在数据丢失（数据先写入磁盘缓冲区而不是磁盘）
            功能较为单一
        场景：
            大数据场景、日志传输搜集等
    （2）RabbitMQ：
            保证数据不丢失
            高可用
            功能强大，支持消息重试、死信队列等
        问题：
            吞吐量不高
            集群部署复杂
            开发语言erlang
    （3）RocketMQ:
            吞吐量很高
            保证数据不丢失
            支持集群部署
            功能高级：延迟消息等
            开发语言Java

消息模型：
    点对点模式： 队列模型， 消息是匿名的， 也即消费者无法申明独立身份
        消息生产者生产消息发送到queue中，然后消息消费者从queue中取出并且消费消息。
        消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。
        Queue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。

    发布订阅模式：
        消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费。
        消费独立：相比队列模型的匿名消费方式，发布订阅模型中消费方都会具备的身份，一般叫做订阅组（订阅关系），不同订阅组之间相互独立不会相互影响。
        基于独立身份的设计，同一个主题内的消息可以被多个订阅组处理，每个订阅组都可以拿到全量消息。因此发布订阅模型可以实现一对多通信。

推拉模型：指的是消费者和broker之间的交互关系
    PULL模式：
         Consumer 主动向 Broker 请求拉取消息，即 Broker 被动的发送消息给 Consumer。
         消息有一定延迟，但是broker设计简化了
    PUSH模式：
        Broker 推向 Consumer，即 Consumer 被动的接收消息，由 Broker 来主导消息的发送。
        实时性好，但是推送速率难以适应消费速率，适用于消息量不大、消费能力强要求实时性高的情况下

    RocketMQ 和 Kafka 都是利用“长轮询”来实现拉模式，用以平衡 Pull/Push 模型各自的缺点。
    一句话说就是消费者和 Broker 相互配合，拉取消息请求不满足条件的时候 hold 住，避免了多次频繁的拉取动作，当消息一到就提醒返回。






RocketMQ: 分布式、高可用、高性能
    基本概念：
        Topic
        MessageType： 普通消息、顺序消息、事务消息和定时/延时消息
        MessageQueue：消息存储和传输的实际容器，也是消息的最小存储单元。 Apache RocketMQ 的所有主题都是由多个队列组成，以此实现队列数量的水平拆分和队列内部的流式存储
        Message: 最小数据传输单元
        MessageQueueOffset： 按消息到达服务端的先后顺序存储在指定主题的多个队列中，每条消息在队列中都有一个唯一的Long类型坐标，这个坐标被定义为消息位点
        ConsumerOffset： 消息被某个消费者消费完成后不会立即从队列中删除，Apache RocketMQ 会基于每个【消费者分组】记录消费过的最新一条消息的位点，即消费位点
        重置消费位点 ： 重新设置消费者分组对已订阅主题的消费进度
        Producer： 构建并传输消息到服务端的运行实体
        TransactionResolution： 事务状态， 事务消息发送过程中，事务提交的状态标识，服务端通过事务状态控制事务消息是否应该提交和投递。事务状态包括事务提交、事务回滚和事务未决
        ConsumerGroup： 承载多个消费行为一致的消费者的负载均衡分组。和消费者不同，消费者分组并不是运行实体，而是一个逻辑资源
        Consumer： 接收并处理消息的运行实体。消费者通常被集成在业务系统中，从服务端获取消息，并将消息转化成业务可理解的信息，供业务逻辑处理
        Subscription ：订阅关系， 消费者获取消息、处理消息的规则和状态配置。订阅关系由消费者分组动态注册到服务端系统，并在后续的消息传输中按照订阅关系定义的过滤规则进行消息匹配和消费进度维护
        消息过滤： 消费者可以通过订阅指定消息标签（Tag）对消息进行过滤，确保最终只接收被过滤后的消息合集。过滤规则的计算和匹配在Apache RocketMQ 的服务端完成
        消息轨迹： 通过消息轨迹，您能清晰定位消息从生产者发出，经由Apache RocketMQ 服务端，投递给消费者的完整链路，方便定位排查问题
        事务消息： 一种高级消息类型，支持在分布式场景下保障消息生产和本地事务的最终一致性， 对于事务消息需要生产者配合进行事务检查等行为保障事务的最终一致性

    概述：
        （1） 异步通信方式
        （2） 发布订阅的消息传输模型

    消息存储：
        队列，消息传输和存储的实际单元容器，类比于其他消息队列中的分区。 Apache RocketMQ 通过流式特性的无限队列结构来存储消息，消息在队列内具备顺序性存储特征。
        Apache RocketMQ 默认提供消息可靠存储机制，所有发送成功的消息都被持久化存储到队列中，配合生产者和消费者客户端的调用可实现至少投递一次的可靠性语义。
    存储机制：
        理论上是无限队列存储，但是肯定有物理限制
        Apache RocketMQ 基于统一的物理日志队列和轻量化逻辑队列的二级组织方式，管理物理数据。这种机制可以带来顺序读写、高吞吐、高性能等优势，但缺点是不支持按主题和队列单独管理。

        存储时长： Apache RocketMQ 使用存储时长作为消息存储的依据，即每个节点对外承诺消息的存储时长。在存储时长范围内的消息都会被保留，无论消息是否被消费；超过时长限制的消息则会被清理掉。
            -> 和消息状态无关也不是按主体或者队列粒度管理的
    顺序消息：顺序消息的顺序关系通过消息组（MessageGroup）判定和识别，发送顺序消息时需要为每条消息设置归属的消息组，相同消息组的多条消息之间遵循先进先出的顺序关系，不同消息组、无消息组的消息之间不涉及顺序性
        在有序事件处理、撮合交易、数据实时增量同步等场景下，异构系统间需要维持强一致的状态同步，上游的事件变更需要按照顺序传递到下游进行处理
        顺序性的保证：
            （1）生产者： 单一生产者，串行发送（不能多线程）
            （2）服务器中同一消息组的消息存储在同一个队列中（按顺序）
            （3）消费者顺序消费
    事务消息：
        实现的分布式事务消息功能，在普通消息基础上，支持二阶段的提交能力。将二阶段提交和本地事务绑定，实现全局提交结果的一致性。
        （1） 生产者将消息发送至服务端（half_commit)。
        （2） 服务端将消息持久化成功之后，向生产者返回Ack确认消息已经发送成功，此时消息被标记为"暂不能投递"，这种状态下的消息即为半事务消息。 ( 半消息不会持久化）
        （3）生产者开始执行本地事务逻辑
        （4）生产者根据本地事务执行结果向服务端提交二次确认结果（Commit或是Rollback），服务端收到确认结果后处理逻辑如下：
            * 二次确认结果为Commit：服务端将半事务消息标记为可投递，并投递给消费者。
            * 二次确认结果为Rollback：服务端将回滚事务，不会将半事务消息投递给消费者。
         (5) 在断网或者是生产者应用重启的特殊情况下，若服务端未收到发送者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，
             服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查。
         (6) 生产者收到消息回查后，需要检查对应消息的本地事务执行的最终结果。
         (7) 生产者根据检查到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤4对半事务消息进行处理。
    消费者分类：
        支持 PushConsumer 、 SimpleConsumer 以及 PullConsumer 这三种类型的消费者
        PushConsumer：高度封装，不够灵活，适用于无自定义流程的业务消息开发场景。
            通过消费监听器处理业务并返回消费结果。消息的获取、消费状态提交以及消费重试都通过 Apache RocketMQ 的客户端SDK完成。
            （1）消费者初始化时注册一个消费监听器，并在消费监听器内部实现消息处理逻辑
            （2）SDK内置了一个长轮询线程（每5秒查看消息是否到了），先将消息异步拉取到SDK内置的缓存队列中，再分别提交到消费线程中，触发监听器执行本地消费逻辑
        SimpleConsumer: 更加灵活
            是一种接口原子型的消费者类型，消息的获取、消费状态提交以及消费重试都是通过消费者业务逻辑主动发起调用完成。
            需要实现：
                (1）消费者主动调用该接口从服务端获取消息（ReceiveMessage)
                (2)消费者成功消费消息后，主动调用该接口向服务端返回消费成功响应。(AckMessage）
               （3）消费重试场景下，消费者可通过该接口修改消息处理时长，即控制消息的重试间隔。（ChangeInvisibleDuration）
            适用场景：
                （1）消息处理时长不可控：如果消息处理时长无法预估，经常有长时间耗时的消息处理情况。建议使用SimpleConsumer消费类型，pushConsumer容易出现无限阻塞
                （2）需要异步化、批量消费等高级定制场景， PushConsumer消息消费不能再次异步化了
                （3）需要自定义消费速率
    消费者负载均衡策略：
        通过消费者负载均衡策略，可将主题内的消息分配给指定消费者分组中的多个消费者共同分担，提高消费并发能力和消费者的水平扩展能力
        PushConsumer 和SimpleConsumer默认适用消息粒度负载均衡， pullConsumer使用队列粒度负载均衡
        消息粒度的策略：
            （1）每个消息给哪一个消费者是随机的不能指定
            （2）消息会先被加锁，保证不会被重复消费，



Kafka: 分布式流处理平台
    适用场景：
        （1） 实时流数据管道，它可以在系统或应用之间可靠地获取数据
        （2）构建实时流式应用程序，对这些流数据进行转换或者影响

    基本特性：
        （1）在Kafka中，客户端和服务器使用一个简单、高性能、支持多语言的 TCP 协议

    核心API：
        The Producer API 允许一个应用程序发布一串流式的数据到一个或者多个Kafka topic。
        The Consumer API 允许一个应用程序订阅一个或多个 topic ，并且对发布给他们的流式数据进行处理。
        The Streams API 允许一个应用程序作为一个流处理器，消费一个或者多个topic产生的输入流，然后生产一个输出流到一个或多个topic中去，在输入输出流中进行有效的转换。
        The Connector API 允许构建并运行可重用的生产者或者消费者，将Kafka topics连接到已存在的应用程序或者数据系统。比如，连接到一个关系型数据库，捕捉表（table）的所有变更内容。

    基本概念：
        （1）topic： 数据主题， 维护一个分区日志， 一个Topic支持多个消费者订阅
        （2）partition： 数据分区保存所有发布的数据， 且顺序保存不可变，到期时间之后删除（也不可以不删除性能几乎没影响）
        （3）分布式：每一个分区都有对应的leader分区负责读写， 和follower分区作为同步备份， 这些分区位于不同机器上，leader故障会进行重新选主。
        （4）生产者：将记录分配到topic的partition中。可以使用循环的方式来简单地实现负载均衡，也可以根据某些语义分区函数(例如：记录中的key)来完成。
        （5）消费者：消费者使用一个 消费组 名称来进行标识，发布到topic中的每条记录被分配给订阅消费组中的一个消费者实例（均衡）

    文件存储：Kafka 对消息的存储和缓存严重依赖于文件系统， 实际上设计合理的磁盘结构通常可以和网络一样快，
        （1）顺序磁盘访问在某些情况下比随机内存访问还要快
        （2）内存作磁盘缓存，受限于容量， 也会增加频繁的容量回收开销
         为什么快：
            （1）磁盘访问模式优化：磁盘使用倾向于顺序读取，基于内核pageCache性能也很高
            （2）避免大量小IO操作：建立在一个 “消息块” 的抽象上，合理将消息分组。 这使得网络请求将多个消息打包成一组，而不是每次发送一条消息，从而使整组消息分担网络中往返的开销。Consumer 每次获取多个大型有序的消息块，并由服务端 依次将消息块一次加载到它的日志中
            （3）服务端自身的持久化操作优化： 避免大量的非必要字节copy, 0拷贝， linux提供的sendFile方法可以高效地将数据从 pagecache 转移到 socket 网络连接中；
            （4）日志发送还可以进一步压缩， 降低带宽占用
    0拷贝：
        传统的IO操作包括四次数据拷贝：涉及四次数据拷贝， 两次系统调用， 四次上下文切换：用户态 - 内核态 - 用户态 - 内核态 - 用户态
            (1) [操作系统] 从磁盘读取数据到内核空间的 pagecache    (DMA拷贝)
            (2) [应用程序] 读取内核空间的数据到用户空间的缓冲区      （CPU拷贝）
            (3) [应用程序] 将数据(用户空间的缓冲区)写回内核空间到套接字缓冲区(内核空间)    (CPU拷贝)
            (4) [操作系统] 将数据从套接字缓冲区(内核空间)复制到通过网络发送的 NIC 缓冲区   （DMA拷贝）

        sendFile 整个过程只有两次上下文切换（用户态-内核态-用户态）和两次 DMA 拷贝，很重要的一点是这里完全不需要 CPU 来进行拷贝了，所以才叫做零拷贝，这里的拷贝指的就是操作系统的层面。

        mmap: 减少一次CPU拷贝
            传统 IO 里面从内核缓冲区到用户缓冲区有一次 CPU 拷贝，从用户缓冲区到 Socket 缓冲区又有一次 CPU 拷贝。
            mmap 则一步到位，直接基于 CPU 将内核缓冲区的数据拷贝到了 Socket 缓冲区。
            之所以能够减少一次拷贝，就是因为 mmap 直接将磁盘文件数据映射到内核缓冲区，这个映射的过程是基于 DMA 拷贝的，同时【用户缓冲区】是跟【内核缓冲区】共享一块映射数据的，建立共享映射之后，就不需要从内核缓冲区拷贝到用户缓冲区了。
            虽然减少了一次拷贝，但是上下文切换的次数还是没变。
            RocketMQ 中就是使用的 mmap 来提升磁盘文件的读写性能。

        DMA： 直接内存访问
            DMA控制器来负责IO数据传输， 而不需要IO介入


    消息丢解决的方案：一般来讲已发送的状态需要在确认消费后改成已消费
        （1）Kafka的 topic 被分割成了一组完全有序的 partition，其中每一个 partition 在任意给定的时间内只能被每个订阅了这个 topic 的 consumer 组中的一个 consumer 消费。
        这意味着 partition 中 每一个 consumer 的位置仅仅是一个数字，即下一条要消费的消息的offset。
        这使得被消费的消息的状态信息相当少，每个 partition 只需要一个数字。这个状态信息还可以作为周期性的 checkpoint。这以非常低的代价实现了和消息确认机制等同的效果。
        （2）消息被所有的副本节点加入到日志中时或者指定的数量, 才算是提交, 只有提交的消息才会被 consumer 消费， 这个语义也可以保证发送的不丢失。

    kafka判断节点存活的方法：
        （1）节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接。
        （2）如果节点是个 follower ，它必须能及时的同步 leader 的写操作，并且延时不能太久。

    Kafka不采用通常的投票方式选leader， 而是维护一个 动态维护了一个同步状态的备份的集合 （a set of in-sync replicas）， 简称 ISR
        在这个集合中的节点都是和 leader 保持高度一致的，只有这个集合的成员才 有资格被选举为 leader，一条消息必须被这个集合 所有 节点读取并追加到日志中了，这条消息才能视为提交
        注意：
        producers 设置 ack 是否提交完成，
         （1）0：不等待broker返回确认消息,
         （2）1: leader保存成功返回或,
         （3）-1(all): 所有备份都保存成功返回.
         请注意. 设置 “ack = all” 并不能保证所有的副本都写入了消息。默认情况下，当 acks = all 时，只要 ISR 副本同步完成，就会返回消息已经写入。
    奋分区分配给消费者有两种策略：
        （1） Range：该策略会把主题的若干个连续的分区分配给消费者
        （2）RoundRobin：把主题的所有分区逐个分配给消费者（交叉分配），消费者之间最多差一个分区

    语义：
        消息送达语义是消息系统中一个常见的问题，主要包含三种语义：可以通过ACK设置、幂等设计、消息消费和offset提交的原子性等实现
        （1）At most once：消息发送或消费至多一次；
        （2）At least once：消息发送或消费至少一次；（ 默认）！
        （3）Exactly once：消息恰好只发送一次或只消费一次；

    Zookeeper作用：Kafka 使用 zk来保存 broker、主题和分区的元数据信息。
        部署的时候可以在一台服务器上同时启动一个 Zookeeper Server 和 一个 Kafka Server，也可以使用已有的其他 Zookeeper 集群。
        （1） broker 注册
        （2） TOPIC 注册
        （3）消费者注册
        （4）消息消费进度Offset 记录
        （5）分区和消费者关系维护
        （6）生产者和消费者的负载均衡













